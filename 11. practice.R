# Напишите функцию corr.calc, которая на вход получает data.frame 
# с двумя количественными переменными, рассчитывает коэффициент 
# корреляции Пирсона и возвращает вектор из двух значений: коэффициент 
# корреляции и p - уровень значимости.

corr.calc <- function(x) {
  library(psych)
  res <- corr.test(x)
  return(c(res$r[2], res$p[2]))
}

corr.calc(mtcars[, c(1,5)]) # expected: 0.6811719078 0.0000177624


# Напишите функцию filtered.cor которая на вход получает data.frame с 
# произвольным количеством переменных (как количественными, так и любых 
# других типов), рассчитывает коэффициенты корреляции Пирсона между всеми 
# парами количественных переменных и возвращает наибольшее по модулю значение 
# коэффициента корреляции. (То есть функция может вернуть -0.9, если это 
# наибольшая по модулю  корреляция).
# Гарантируется наличие в data.frame хотя бы двух количественных переменных.

step6 <- read.table("step6.csv",  header=TRUE, sep=',' )

filtered.cor <- function(x) {
  x <- Filter(is.numeric, x) # оставляем только количественные переменные
  cr <- cor(x) # строим таблицу корреляций
  diag(cr) <- 0 # зануляем диагональ (кореллция переменной с самой собой)
  return(cr[which.max(abs(cr))]) # возвращаем максимальное по модулю значение
}

filtered.cor(step6) # expected: 0.235997


# Напишите функцию smart_cor, которая получает на вход dataframe с двумя 
# количественными переменными. Проверьте с помощью теста Шапиро-Уилка, 
# что данные в обеих переменных принадлежат нормальному распределению.
# Если хотя бы в одном векторе распределение переменной отличается от 
# нормального (p - value меньше 0.05), то функция должна возвращать 
# коэффициент корреляции Спирмена. (Числовой вектор из одного элемента).
# Если в обоих векторах распределение переменных от нормального значимо не 
# отличается, то функция должна возвращать коэффициент корреляции Пирсона.

test_data  <- read.csv("https://stepik.org/media/attachments/course/129/test_data.csv")

smart_cor <- function(x) {
  is_norm <- shapiro.test(x[,1])$p > 0.05 & shapiro.test(x[,2])$p > 0.05
  if (is_norm) {
    #print('Normies -> Pearson')
    return(cor(x = x[,1], y = x[,2], method = 'pearson'))
  }
  else {
    #print('Wierdos -> Spearman')
    return(cor(x = x[,1], y = x[,2], method = 'spearman'))
  }
}

smart_cor(test_data) # expected: -0.1031003


# Скачайте набор данных - dataframe с двумя количественными переменными 
# (вспомните при необходимости, как задавать разделитель и другие параметры 
# функции read.table), постройте линейную регрессию, где - первая 
# переменная - зависимая, вторая - независимая. В ответ укажите значения 
# регрессионных коэффициентов сначала intercept затем  slope.
# Десятичный разделитель - точка. В поле для ответа введите два числа, 
# не округляйте значения

filename <- 'dataset_11508_12.txt'
df <- read.table(filename, sep = ' ')

library(ggplot2)
ggplot(df, aes(x = V2, y = V1))+
  geom_point(size = 3)+
  geom_smooth(method = 'lm')

fit <- lm(V1 ~ V2, df)
summary(fit)

fit$coefficients


# Воспользуемся уже знакомыми данными diamonds из библиотеки ggplot2. 
# Только для бриллиантов класса Ideal (переменная cut) c числом карат 
# равным 0.46 (переменная carat) постройте линейную регрессию, где в качестве 
# зависимой переменной выступает price, в качестве предиктора - переменная  
# depth. Сохраните коэффициенты регрессии в переменную fit_coef.

df <- subset(x = diamonds, subset = (cut == 'Ideal') & (carat == 0.46))
fit <- lm(price ~ depth, df)
fit_coef <- fit$coefficients


# Напишите функцию regr.calc, которая на вход получает dataframe c двумя 
# переменными. Если две переменные значимо коррелируют (p - уровень значимости 
# для коэффициента корреляции Пирсона меньше 0.05), то функция строит 
# регрессионную модель, где первая переменная - зависимая, вторая - 
# независимая. Затем создает в dataframe новую переменную с назанием fit, 
# где сохраняет предсказанные моделью значения зависимой переменной. В 
# результате функция должна возвращать исходный dataframe с добавленной 
# новой переменной fit.
# Если две переменные значимо не коррелируют, то функция возвращает строчку 
# "There is no sense in prediction"

regr.calc <- function(x) {
  cor_p <- cor.test(x[,1], x[,2], method = 'pearson')$p.value
  if (cor_p < 0.05) {
    x$fit <- lm(x[,1] ~ x[,2])$fitted.values
    return(x)
  }
  else {
    return("There is no sense in prediction")
  }
}

my_df = iris[,1:2] # на вход подаем данные iris только с переменными Sepal.Length и Sepal.Width
regr.calc(iris[,1:2]) # переменные значимо не коррелируют 


my_df = iris[,c(1,4)] # на вход подаем данные iris только с переменными Sepal.Length и Petal.Width
regr.calc(my_df) # переменные значимо коррелируют 


# Постройте scatterplot по данным iris, сохранив его в переменную my_plot : 
# Ось X - переменная Sepal.Width
# Ось Y -  переменная Petal.Width
# Цвет точек - переменная Species
# Также добавьте линейное сглаживание для каждой группы наблюдений по переменной Species.

my_plot <- ggplot(iris, aes(x = Sepal.Width, y = Petal.Width, col = Species))+
  geom_point(size = 3)+
  geom_smooth(method = 'lm')

